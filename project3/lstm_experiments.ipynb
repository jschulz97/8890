{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, outputs):\n",
    "        super(myLSTM, self).__init__()\n",
    "\n",
    "        self.model = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(hidden_size, outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape (batch, time_step, input_size)\n",
    "        # r_out shape (batch, time_step, output_size)\n",
    "        # h_n shape (n_layers, batch, hidden_size)\n",
    "        # h_c shape (n_layers, batch, hidden_size)\n",
    "        r_out, (h_n, h_c) = self.model(x, None)   # None represents zero initial hidden state\n",
    "\n",
    "        # choose r_out at the last time step\n",
    "        out = self.out(r_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Dataset (Numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 2000\n",
    "num_classes = 10\n",
    "batch_size = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "numbers_train_forwards = [0,1,2,3,4,5,6,7,8,9,0]\n",
    "numbers_train_backwards = [0,9,8,7,6,5,4,3,2,1,0]\n",
    "numbers_train_i = [0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 1.4593\n",
      "Epoch [200/2000], Loss: 0.9514\n",
      "Epoch [300/2000], Loss: 0.7341\n",
      "Epoch [400/2000], Loss: 0.6174\n",
      "Epoch [500/2000], Loss: 0.5493\n",
      "Epoch [600/2000], Loss: 0.5062\n",
      "Epoch [700/2000], Loss: 0.4744\n",
      "Epoch [800/2000], Loss: 0.4406\n",
      "Epoch [900/2000], Loss: 0.3719\n",
      "Epoch [1000/2000], Loss: 0.2360\n",
      "Epoch [1100/2000], Loss: 0.1783\n",
      "Epoch [1200/2000], Loss: 0.1487\n",
      "Epoch [1300/2000], Loss: 0.1240\n",
      "Epoch [1400/2000], Loss: 0.1023\n",
      "Epoch [1500/2000], Loss: 0.0837\n",
      "Epoch [1600/2000], Loss: 0.0682\n",
      "Epoch [1700/2000], Loss: 0.0554\n",
      "Epoch [1800/2000], Loss: 0.0448\n",
      "Epoch [1900/2000], Loss: 0.0360\n",
      "Epoch [2000/2000], Loss: 0.0287\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "import random\n",
    "\n",
    "# Create model\n",
    "net = myLSTM(5, 8, 1, 10)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i in numbers_train_i[0:5]:\n",
    "        ## Forward numbers\n",
    "        input_tensor = torch.Tensor([numbers_train_forwards[i:i+5]]).unsqueeze(0)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(input_tensor)\n",
    "\n",
    "        label = torch.LongTensor([numbers_train_forwards[i+5]])\n",
    "        loss = criterion(outputs, label)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "        ## Backward numbers\n",
    "        input_tensor = torch.Tensor([numbers_train_backwards[i:i+5]]).unsqueeze(0)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(input_tensor)\n",
    "\n",
    "        label = torch.LongTensor([numbers_train_backwards[i+5]])\n",
    "        loss = criterion(outputs, label)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORWARDS\n",
      "input: [[[0. 1. 2. 3. 4.]]] output: tensor([5])\n",
      "input: [[[1. 2. 3. 4. 5.]]] output: tensor([6])\n",
      "input: [[[2. 3. 4. 5. 6.]]] output: tensor([7])\n",
      "input: [[[3. 4. 5. 6. 7.]]] output: tensor([8])\n",
      "input: [[[4. 5. 6. 7. 8.]]] output: tensor([9])\n",
      "BACKWARDS\n",
      "input: [[[0. 9. 8. 7. 6.]]] output: tensor([5])\n",
      "input: [[[9. 8. 7. 6. 5.]]] output: tensor([4])\n",
      "input: [[[8. 7. 6. 5. 4.]]] output: tensor([3])\n",
      "input: [[[7. 6. 5. 4. 3.]]] output: tensor([2])\n",
      "input: [[[6. 5. 4. 3. 2.]]] output: tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# test_set = [[0],[9],[8],[7],[6]]\n",
    "\n",
    "# Test the model\n",
    "net.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    print('FORWARDS')\n",
    "    for i in numbers_train_i[0:5]:\n",
    "        ## Forward numbers\n",
    "        input_tensor = torch.Tensor([numbers_train_forwards[i:i+5]]).unsqueeze(0)\n",
    "\n",
    "        outputs = net(input_tensor)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print('input:', np.array(input_tensor), 'output:', predicted)\n",
    "    \n",
    "    print('BACKWARDS')\n",
    "    for i in numbers_train_i[0:5]:\n",
    "        ## Forward numbers\n",
    "        input_tensor = torch.Tensor([numbers_train_backwards[i:i+5]]).unsqueeze(0)\n",
    "\n",
    "        outputs = net(input_tensor)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print('input:', np.array(input_tensor), 'output:', predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: 0 output: tensor([1])\n",
      "input: 9 output: tensor([0])\n",
      "input: 8 output: tensor([8])\n",
      "input: 7 output: tensor([7])\n",
      "input: 6 output: tensor([6])\n",
      "input: 5 output: tensor([5])\n",
      "input: 4 output: tensor([3])\n",
      "input: 3 output: tensor([3])\n",
      "input: 2 output: tensor([2])\n",
      "input: 1 output: tensor([0])\n"
     ]
    }
   ],
   "source": [
    "# test_set = [0,1,2,3,4,5,6,7,8,9]\n",
    "test_set = [0,9,8,7,6,5,4,3,2,1]\n",
    "\n",
    "# Test the model\n",
    "net.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    for test_num in test_set:\n",
    "        outputs = net(torch.Tensor([test_num]).unsqueeze(0).unsqueeze(0))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print('input:', test_num, 'output:', predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6c063a99f4b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "net.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper parameters\n",
    "num_epochs = 2\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "# new_mirror = 'https://ossci-datasets.s3.amazonaws.com/mnist'\n",
    "# torchvision.datasets.MNIST.resources = [\n",
    "#    ('/'.join([new_mirror, url.split('/')[-1]]), md5)\n",
    "#    for url, md5 in torchvision.datasets.MNIST.resources\n",
    "# ]\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='data',\n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='data',\n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 1.1874\n",
      "Epoch [1/2], Step [200/600], Loss: 0.6303\n",
      "Epoch [1/2], Step [300/600], Loss: 0.5380\n",
      "Epoch [1/2], Step [400/600], Loss: 0.3587\n",
      "Epoch [1/2], Step [500/600], Loss: 0.3171\n",
      "Epoch [1/2], Step [600/600], Loss: 0.1807\n",
      "Epoch [2/2], Step [100/600], Loss: 0.2073\n",
      "Epoch [2/2], Step [200/600], Loss: 0.3109\n",
      "Epoch [2/2], Step [300/600], Loss: 0.3576\n",
      "Epoch [2/2], Step [400/600], Loss: 0.2271\n",
      "Epoch [2/2], Step [500/600], Loss: 0.2429\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1052\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "net = myLSTM(28, 64, 1, 10)\n",
    "net = net.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = net(images.squeeze(1))\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5,\n",
      "        4, 0, 7, 4, 0, 1, 3, 1, 3, 6, 7, 2, 7, 1, 2, 1, 1, 7, 4, 6, 3, 5, 1, 2,\n",
      "        4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0,\n",
      "        2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4,\n",
      "        1, 7, 6, 9], device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-ece8be37f6b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "net.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images.squeeze())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(predicted)\n",
    "        input()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "net.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images.squeeze())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        print(images.shape, predicted.shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
